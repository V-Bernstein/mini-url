This application serves as an API for a URL shortening service, akin to TinyUrl. As per the problem statement, there are two endpoints:
-"/shorten", which is a POST call that takes a URL and creates a shortened URL that "points" to the given URL.
-"/{url}", which is a GET call that takes a mini URL and returns the original URL

I chose a mini URL length of 6 characters. These can be lower case a-z, and digits 0-9. This gives us a range of (26 + 10) ^ 6, which is 2,176,782,336 (~2 billion) possible URLs. For the first 2 billion URLs we shorten we'll start with 'aaaaaa' and increment ('aaaaab', 'aaaaac', ...) for each new URL. Once we reach '999999' we wrap around to 'aaaaaa' again. Then we'll update the existing record with the new full URL. This keeps our database (locally a MySQL DB running in Docker) from becoming too large, and it should be quick with indexes on the ID and the mini URL. The INT type in MySQL has a maximum value of over 4 billion, so we won't run out of unique IDs.

Of note, this is succeptible to a DOS-style attack, where the attacker can spam the shorten API to overwrite the entire DB with their (possibly malicious) URL. One way to address this is to limit access to the shorten URL based on IP. Alternatively, we could require an account to use the API, and limit the account to a certain number of shortened URLs.

It is also possible to have 2 billion legitimate shorten requests within a small window. This would cause the service to be unstable, where you might not recieve the URL you wanted with a mini URL. I consider this beyond the scope of this exercise, but would look at increasing the length of the mini URL, or restricting the creation of new URLs until the oldest URL is 2 days old (a somewhat arbitrary length I'd expect a shortened URL to remain available). (This certainly presents its own issues too.)

To address some of the prompts: due to the circular nature of the implementation, URLs will expire when they are overwritten, 2 billion creations later. Until then they are valid. This raises the concern about what if the URL is no longer useful (it returns 404 for example). I treat this the same way I treat improperly formatted URLs: it's up to the user. If they want to shorten a nonsense string ("The quick brown fox") they are welcome to do that. Similarly, we won't protect users from malicious URLs. (One way I can think of to accomplish that would be to spin up an isolated VM and access any URL that is shortened. Then check for malicious behavior, and block the creation of that URL if bad behavior is detected. This is not a simple problem or solution though.)

If a user inputs a mini URL that does not follow the above format, we throw an error on the endpoint. The exception is if they input a URL with upper-case characters. The URL standards says URLs should be case-agnostic, so in this case we convert the URL to lower-case and proceed from there.

Something that often happens to URLs is that they might see a huge increase in traffic, attributed to "going viral". A cache would be a good way of dealing with this traffic, as it would decrease load on the DB. That specific URL would be getting accessed a lot, so an LRU cache, hosted on something like a Gemfire server, would fit the bill.

My implementation could be simplified: instead of storing the mini URL, it could be calculated based on the ID. 'aaaaaa' would be 1, 'aaaaab' is 2, ..., '999999' is 36^6. We would take in a mini URL, translate it, and then search by ID. I didn't have time to implement that for this challenge. There are some TODOs around error and exception handling where I ran out of time to implement it properly.